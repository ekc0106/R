---
데마 hw3
---
#1. 3장 연습문제 7에서 Breast Cancer 데이터만 해 볼 것. (c)의 경우 R의 caret 패키지를 이용할 수 있음.
7. (a) 클래스별로 다른 색 또는 기호를 이용하여 입력변수들 간의 산점도 행렬을 그려라. 자료에 주목할 만 한 어떤 특성(ex. 정규성or 공분산 행렬의 동일성 etc..)이 있는가?
```{r}
library(mlbench)
data("BreastCancer")
sum(is.na(BreastCancer)) #NA값이 있기에 생략해보자.
bc <- na.omit(BreastCancer[,-1])
str(bc)
bc$Class <- as.numeric(bc$Class)
bc <- apply(bc,2,as.numeric)
bc <- data.frame(bc)
plot(bc[,-ncol(bc)], col = c(2,4)[bc$Class], pch = c(19,4)[bc$Class])
# 산점도를 그려본 결과, 클래스에 따라 다른 입력변수들의 분포가 확연히 구분지어짐을 알 수 있다.
# 모든 변수들에서 Class 1이 2보다 왼쪽 아래에 있음을 알 수 있다.
library(biotools)
boxM(bc[,-ncol(bc)],bc$Class)
#p-value 가 매우 작으므로 등분산 행렬의 동일하다는 귀무가설을 기각한다
```
(b) 자료를 랜덤하게 7:3으로 훈련 및 시험자료로 나눈 후, 시험자료에 대하여 선형판별분석, 이차판별분석, 로지스틱 회귀의 예측력을 비교한다. 객관적인 비교를 위해 랜덤분할을 50회 실시하여 오분류율의 평균 및 표준 오차값을 비교하라.
```{r}
n <- nrow(bc)
fmla <- as.formula(paste("Class",'~',paste(colnames(bc[,-ncol(bc)]),collapse='+')))
bc$Class <- bc$Class - 1
Result <- matrix(0,50,3)
for (i in 1:50){
  set.seed(i)
  train_index <- sample(1:n,size=floor(0.7*n))
  train <- bc[train_index,] ; test <- bc[-train_index,]
  lda1 <- lda(fmla,data=train)
  pre1 <- predict(lda1,test[,-ncol(test)])
  Result[i,1] <- sum(pre1$class!=test$Class)/length(test$Class)
  qda1 <- qda(fmla,data=train)
  pre2 <- predict(qda1,test[,-ncol(test)])
  Result[i,2] <- sum(pre2$class!=test$Class)/length(test$Class)
  logi1 <- glm(fmla, data=train, family = binomial('logit'))
  pre3 <- predict(logi1, test[,-ncol(test)],type='response')
  predicted <- ifelse(pre3>=0.5,1,0)
  Result[i,3] <- sum(predicted!=test$Class)/length(test$Class)
}
#mean & S.E
for(i in 1:3){
  cat(mean(Result[,i]),sd(Result[,i])/sqrt(length(Result[,i])),'\n')
}
for(i in 1:3){
  cat(c('선형판별분석 오분류율 CI : ','이차판별분석 오분류율 CI : ','로지스틱 회귀 오분류율 CI : ')[i],
      '[',mean(Result[,i])-1.96*sd(Result[,i])/sqrt(length(Result[,i])),',',
      mean(Result[,i])+1.96*sd(Result[,i])/sqrt(length(Result[,i])),']','\n')
}
#결과를 보았을 때, 각 95%신뢰구간의 겹치는 부분도 거의 없었으며, 로지스틱 회귀에서 오분류율이 제일 적었고, 이차 판별 분석에서 제일 컸다.
```
(c) 각 랜덤 분할에서 훈련자료에 대하여 10-묶음 교차확인 오차에 의해 오분류율값을 계산하고 평균과 표준오차를 구하라. 이 값들을 (b)에서 구한 시험오차의 평균과 표준오차와 비교하라.
```{r}
library(cvTools)
cross <- cvFolds(nrow(bc),K=10)
Result1 <- matrix(0,10,3)
for(i in 1:10){
  test_index <- cross$subsets[cross$which==i]
  test <- bc[test_index,] ; train <- bc[-test_index,]
  lda1 <- lda(fmla,data=train)
  pre1 <- predict(lda1,test[,-ncol(test)])
  Result1[i,1] <- sum(pre1$class!=test$Class)/length(test$Class)
  qda1 <- qda(fmla,data=train)
  pre2 <- predict(qda1,test[,-ncol(test)])
  Result1[i,2] <- sum(pre2$class!=test$Class)/length(test$Class)
  logi1 <- glm(fmla, data=train, family = binomial('logit'))
  pre3 <- predict(logi1, test[,-ncol(test)],type='response')
  predicted <- ifelse(pre3>=0.5,1,0)
  Result1[i,3] <- sum(predicted!=test$Class)/length(test$Class)
}
Result1
for(i in 1:3){
  cat(mean(Result1[,i]),sd(Result1[,i])/sqrt(length(Result1[,i])),'\n')
}
for(i in 1:3){
  cat(c('선형판별분석 오분류율 CI : ','이차판별분석 오분류율 CI : ','로지스틱 회귀 오분류율 CI : ')[i],
      '[',mean(Result1[,i])-1.96*sd(Result1[,i])/sqrt(length(Result1[,i])),',',
      mean(Result1[,i])+1.96*sd(Result1[,i])/sqrt(length(Result1[,i])),']','\n')
}
# 위의 (b)와 비교했을 때, 이차판별 분석에서의 오분류율의 평균은 줄었고, 일차판별분석과 로지스틱 회귀에서의 오분류율의 평균을 증가하였다. 반복수가 줄은 탓에 SE가 커졌음을 알 수 있다.
```
#2. CDC 2010 출생률 데이터에 대하여 atRisk를 출력변수로 하는 로지스틱 회귀에서 AIC와 BIC를 이용하여 forward로 변수 선택을 해보고 최종적으로 선택된 모형들을 비교하시오.
```{r}
load("C:/Users/kyucheol/Desktop/학교생활/과제/4학년 1학기/데이터마이닝/NatalRiskData.rData")
str(sdata)
for(i in 1:ncol(sdata)){
  sdata[[i]] <- as.numeric(sdata[[i]])
}
fmla <- as.formula(paste("atRisk",'~',paste(colnames(sdata[,-(ncol(sdata)-2)]),collapse='+')))
glm_2 <- glm(atRisk~1, data=sdata, family = binomial('logit'))
glm.aic <- step(glm_2,fmla,direction = 'forward')
glm.bic <- step(glm_2,fmla,direction = 'forward',k=log(nrow(sdata)))
summary(glm.aic)
summary(glm.bic)
# 그 결과, AIC로 찾은 모형에서는 $atRisk ~ DBWT + ULD_MECO + PWGT + GESTREC3 + UPREVIS + ULD_BREECH + ORIGRANDGROUP + URF_PHYPER + CIG_REC$,
# BIC로 찾은 모형에서는atRisk ~ DBWT + ULD_MECO + PWGT + GESTREC3 이 나왔다. BIC로 찾은 모형이 AIC로 찾은 모형에 비해 변수를 적게 사용하였는데 이는 BIC가 변수에 대한 가중치를 높게 주기 때문이다.
```